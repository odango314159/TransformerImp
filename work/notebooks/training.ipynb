{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e378af7f-326e-4054-8a84-117d64f86bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9ede31-2341-4a7d-9c9d-0eaff0deecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = os.getcwd()\n",
    "parent_dir = os.path.dirname(notebook_path)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a4083f2-92ee-4fdc-b3f5-b539cf829316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importnb\n",
    "with __import__('importnb').Notebook(): \n",
    "    from utils.TransformerDataset import MyDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0443a833-8018-432e-b239-c591cbf788b8",
   "metadata": {},
   "source": [
    "## 各パラメータの指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c72b52a8-92e8-44d3-9605-d4e5d8561bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/config.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "    \n",
    "max_len = config[\"max_len\"]\n",
    "src_vocab_size = config[\"src_vocab_size\"]\n",
    "tgt_vocab_size = config[\"tgt_vocab_size\"]\n",
    "batch_size = 16\n",
    "num_head = 8\n",
    "d_model = 64\n",
    "d_ff =1024\n",
    "N = 6\n",
    "pad_idx = 0\n",
    "dropout_rate=0.1\n",
    "layer_norm_eps = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d47d0-5436-4be7-83c1-1db47011c533",
   "metadata": {},
   "source": [
    "## Datasetの読み込み、DataLoaderへの変形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb73f1f-3766-4584-adbc-eb03ac6bede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load('../data/train_data.pth')\n",
    "test_data = torch.load('../data/test_data.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b3acc8-0f2c-4abd-956e-439b0ace3bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data,batch_size=16,shuffle=True,drop_last=True)\n",
    "test_loader = DataLoader(test_data,batch_size=16,shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4298497d-32bc-4848-9b1b-afa948ae213b",
   "metadata": {},
   "source": [
    "## 辞書の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e75546e-0e5f-4dc7-81bb-2dd4af82648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "vocab_en = torch.load('../data/vocab_en.pth')\n",
    "vocab_ja = torch.load('../data/vocab_ja.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aef7fe-16f1-4f56-b05a-01c69dc352de",
   "metadata": {},
   "source": [
    "### 一応データセット、辞書の確認　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "778d9ab7-4db3-4e9c-889f-e4da066baee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文章の量は16\n",
      "en_textのshapeはtorch.Size([16, 159])\n",
      "最初のencoding文はtensor([   3,  858,  127,  188,   22, 1338, 1433,   12,  174, 3847,  650,   16,\n",
      "          70,  737,    6,  120,  323,    8, 2535,   42,  610,    7,    2,    0,\n",
      "           0,    0,    0,    0,    0,    0])\n",
      "辞書の最初の30文字は['<pad>', '<unk>', '<eos>', '<bos>', 'the', ',', 'of', '.', 'and', 'in', '(', ')', 'to', 'was', 'a', '\"', 'is', 'as', \"'s\", 'that', 'by', 'kyoto', 'for', 'it', 'his', 'university', 'with', 'he', 'emperor', '-']\n",
      "文の最大長さは159\n",
      "------------------------------------------------\n",
      "文章の量は16\n",
      "ja_textのshapeはtorch.Size([16, 159])\n",
      "最初のencoding文はtensor([3069, 4257,  623,   28,  145,   45,  380,   48,    5,  311,  190,    6,\n",
      "          38,   23,   12,    8,  683,   13,   21,   10,   43,   17,   22,   10,\n",
      "           7,    0,    0,    0,    0,    0])\n",
      "辞書の最初の30文字は['<pad>', '<unk>', '<eos>', '<bos>', 'の', '、', 'に', '。', 'は', 'を', 'る', 'た', 'て', 'と', 'し', '（', '）', 'が', 'い', '年', 'で', 'な', 'あ', 'っ', 'れ', '・', 'さ', 'り', '-', '京都']\n",
      "文の最大長さは159\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tmp = iter(train_loader)\n",
    "ja_text = 0\n",
    "en_text = 0\n",
    "for batch in tmp:\n",
    "  ja_text,en_text = batch\n",
    "  print(\"文章の量は{}\".format(len(en_text)))\n",
    "  print(\"en_textのshapeは{}\".format(en_text.shape))\n",
    "  print(\"最初のencoding文は{}\".format(en_text[0][0:30]))\n",
    "  print(\"辞書の最初の30文字は{}\".format(vocab_en.lookup_tokens(range(30))))\n",
    "  print(\"文の最大長さは{}\".format(len(en_text[0])))\n",
    "  print(\"------------------------------------------------\")\n",
    "  print(\"文章の量は{}\".format(len(ja_text)))\n",
    "  print(\"ja_textのshapeは{}\".format(ja_text.shape))\n",
    "  print(\"最初のencoding文は{}\".format(ja_text[0][0:30]))\n",
    "  print(\"辞書の最初の30文字は{}\".format(vocab_ja.lookup_tokens(range(30))))\n",
    "  print(\"文の最大長さは{}\".format(len(ja_text[0])))\n",
    "  print(\"------------------------------------------------\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78017dd3-26d1-4d2d-a14f-93558de304d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos> annual buddhist service for dedicating gratitude to priest shinran-october 18th is when lectures of some faculties and departments are off . <eos>\n",
      "-------------------------------------------\n",
      "報恩 講 法要 - 10 月 18 日 、 学部 学科 に よ っ て は 休講 と な る こと が あ る 。\n"
     ]
    }
   ],
   "source": [
    "words = [vocab_en.lookup_token(index) for index in en_text[0].tolist() if vocab_en.lookup_token(index) != '<pad>']\n",
    "sentence = ' '.join(words)\n",
    "print(sentence)\n",
    "print('-------------------------------------------')\n",
    "words = [vocab_ja.lookup_token(index) for index in ja_text[0].tolist() if vocab_ja.lookup_token(index) != '<pad>']\n",
    "sentence = ' '.join(words)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd665ab6-b105-4f57-bc05-b0c3a68cb90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58b6411-90be-4779-b1cc-b98b5601844b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
